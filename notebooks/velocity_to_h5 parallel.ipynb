{
 "cells": [
  {
   "source": [
    "# Synthetic model building #\n",
    "Create thousands of random geologic models for ML (parallel implementation with Dask)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import velocity.mdlbuild as mdlbuild\n",
    "from scaas.wavelet import ricker\n",
    "from utils.ptyprint import progressbar\n",
    "import utils.rand as rndut\n",
    "import deeplearn.utils as dlut\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from utils.signal import bandpass\n",
    "import h5py\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the total number of velocity/reflectivity models\n",
    "n_samples = 2000\n",
    "\n",
    "# Create lists to store the models \n",
    "VEL = []      # Contains velocity models \n",
    "REF = []      # Contains reflectivity models\n",
    "IMG = []      # Contains 'fake' seismic images after convolving reflectivity with a depth                       dependent wavelet\n",
    "VEL_MIG = []  # Contains migration (smoothed) velocity models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# First, I define a serial modeling function, which takes the model ID as the only input.\n",
    "# The serial modeling function builds velocity/reflectivity distributions from a number of geologic events \n",
    "def stdmodel(i):\n",
    "    \"\"\"\n",
    "    Input:   [int] \n",
    "        model ID    \n",
    "\n",
    "    Outputs: [2D numpy arrays]\n",
    "        velr        - real velocity model\n",
    "        data_vel_s  - migration velocity model\n",
    "        ref         - reflectivity model\n",
    "        img         - fake seismic image\n",
    "    \"\"\"\n",
    "    # Dimensions of the model\n",
    "    nz = 1000; dz = 12.0\n",
    "    nx = 1000; dx = 25.0\n",
    "    ny = 20;   dy = 25.0; slcy = 10\n",
    "    \n",
    "    # Velocity limits \n",
    "    minvel = 1600; maxvel = 5500\n",
    "\n",
    "    # Create model building object\n",
    "    mb = mdlbuild.mdlbuild(nx,dx,ny,dy,dz,basevel=maxvel)\n",
    "    \n",
    "    # Generate the v(z) velocity gradient, defining the number of deposition layers and their       thicknesses  \n",
    "    nlayer = 20\n",
    "    props = mb.vofz(nlayer,minvel,maxvel)\n",
    "    thicks = np.random.randint(40,61,nlayer)\n",
    "    \n",
    "    # Determine the folding layers. The first argument controls the number of layers to             fold and the last determines the minimum spacing between the layers to be folded\n",
    "    sqlyrs = sorted(mb.findsqlyrs(3,nlayer,5))\n",
    "    print(\"Folding lyrs %d, %d and %d\"%(sqlyrs[0],sqlyrs[1],sqlyrs[2]))\n",
    "    \n",
    "    # Loop over all deposits to create the model. It builds the model from top to bottom.\n",
    "    csq = 0\n",
    "    for ilyr in progressbar(range(nlayer), \"ndeposit:\", 40):\n",
    "        mb.deposit(velval=props[ilyr],thick=thicks[ilyr],layer=150,layer_rand=0.00,                         dev_layer=0.1)\n",
    "        # Random folding\n",
    "        if(ilyr in sqlyrs):\n",
    "            if(sqlyrs[csq] < 15):\n",
    "                # Random amplitude variation in the folding\n",
    "                amp = np.random.rand()*(3000-500) + 500 \n",
    "                mb.squish(amp=amp,azim=90.0,lam=0.4,rinline=0.0,rxline=0.0,mode='perlin')\n",
    "            elif(sqlyrs[csq] >= 15 and sqlyrs[csq] < 18):\n",
    "                amp = np.random.rand()*(1800-500) + 500 \n",
    "                mb.squish(amp=amp,azim=90.0,lam=0.4,rinline=0.0,rxline=0.0,mode='perlin')\n",
    "            else:\n",
    "                amp = np.random.rand()*(500-300) + 300\n",
    "                mb.squish(amp=amp,azim=90.0,lam=0.4,rinline=0.0,rxline=0.0,mode='perlin')\n",
    "            csq += 1\n",
    "\n",
    "    # Water deposit\n",
    "    #mb.deposit(1480,thick=50,layer=150,dev_layer=0.0)\n",
    "        \n",
    "    # Smooth any unconformities\n",
    "    mb.smooth_model(rect1=1,rect2=5,rect3=1)\n",
    "\n",
    "    # Trim model before faulting\n",
    "    mb.trim(0,nz+100)\n",
    "\n",
    "    # Fault it up!\n",
    "    azims = [0.0,180.0]\n",
    "    fprs  = [True,False]\n",
    "\n",
    "    # Large faults\n",
    "    nlf = np.random.randint(2,5)\n",
    "    for ifl in progressbar(range(nlf), \"nlfaults:\", 40):\n",
    "        azim = np.random.choice(azims)\n",
    "        fpr  = np.random.choice(fprs)\n",
    "        xpos = rndut.randfloat(0.1,0.9)\n",
    "        mb.largefault(azim=azim,begz=0.65,begx=xpos,begy=0.5,dist_die=2.0,tscale=6.0,fpr=fpr,               twod=True)\n",
    "\n",
    "    # Medium faults\n",
    "    nmf = np.random.randint(3,6)\n",
    "    for ifl in progressbar(range(nmf), \"nmfaults:\", 40):\n",
    "        azim = np.random.choice(azims)\n",
    "        fpr  = np.random.choice(fprs)\n",
    "        xpos = rndut.randfloat(0.05,0.95)\n",
    "        mb.mediumfault(azim=azim,begz=0.65,begx=xpos,begy=0.5,dist_die=2.0,tscale=3.0,fpr=fpr,              twod=True)\n",
    "\n",
    "    # Small faults (sliding or small)\n",
    "    nsf = np.random.randint(5,10)\n",
    "    for ifl in progressbar(range(nsf), \"nsfaults:\", 40):\n",
    "        azim = np.random.choice(azims)\n",
    "        xpos = rndut.randfloat(0.05,0.95)\n",
    "        zpos = rndut.randfloat(0.2,0.5)\n",
    "        mb.smallfault(azim=azim,begz=zpos,begx=xpos,begy=0.5,dist_die=2.0,tscale=2.0,fpr=fpr,               twod=True)\n",
    "\n",
    "    # Tiny faults\n",
    "    ntf = np.random.randint(5,10)\n",
    "    for ifl in progressbar(range(ntf), \"ntfaults:\", 40):\n",
    "        azim = np.random.choice(azims)\n",
    "        xpos = rndut.randfloat(0.05,0.95)\n",
    "        zpos = rndut.randfloat(0.15,0.3)\n",
    "        mb.tinyfault(azim=azim,begz=zpos,begx=xpos,begy=0.5,dist_die=2.0,tscale=2.0,fpr=fpr,                twod=True)\n",
    "\n",
    "    # Get model\n",
    "    vel = gaussian_filter(mb.vel[:,:nz],sigma=0.5).astype('float32')\n",
    "    \n",
    "    # Ensure that vmax == 5500 m/s\n",
    "    vel = np.where(vel <= vmax, vel, vmax)\n",
    "\n",
    "    # Resize the output. For my implementation I used 256*256 images.\n",
    "    nzo = 256; nxo = 256\n",
    "    velr = dlut.resample(vel,[nxo,nzo],kind='quintic')\n",
    "    \n",
    "    # Convert from m/s to km/s for numerical stability\n",
    "    velr /= 1000.\n",
    "\n",
    "    # Impose a flat 1.5 km/s watter bottom at the top of the model for simplicity\n",
    "    velr[:,0:10]=1.5\n",
    "    \n",
    "    # Calculate reflectivity and shift to match vel in depth\n",
    "    refr = mb.calcrefl2d(velr)\n",
    "    \n",
    "    # Get migration velocity model\n",
    "    #data_vel_s, refl =vel_smooth(velr)\n",
    "    data_vel_s = gaussian_filter(velr,sigma=1).astype('float32')\n",
    "    #data_vel_s[:,0:10]=1.5 # Uncomment to impose non-smooth water bottom for migration                                       filtering  \n",
    "\n",
    "    # Create a fake migrated image\n",
    "    # Ricker wavelet parameters\n",
    "    nt = 250; ot = 0.0; dt = 0.001; ns = int(nt/2)\n",
    "    amp = 1.0; dly = 0.125\n",
    "    minf = 99.0; maxf = 140.0\n",
    "    # Compute ricker wavelet with random frequency \n",
    "    f = rndut.randfloat(minf,maxf)\n",
    "    wav = ricker(nt,dt,f,amp,dly)\n",
    "\n",
    "    # Convolve with reflectivity\n",
    "    img = dlut.normalize(np.array([np.convolve(refr[ix,:],wav) for ix in range(nxo)])[:,ns:nzo+ns])\n",
    "    # Create noise\n",
    "    # nze = dlut.normalize(bandpass(np.random.rand(nxo,nzo)*2-1, 2.0, 0.01, 2, pxd=43))/                                        rndut.randfloat(3,5)\n",
    "    # img += nze\n",
    "\n",
    "    # correct odd shift in depth\n",
    "    # img = np.roll(img,2)\n",
    "    # img[:,0:10]=0.\n",
    "    # refr = np.roll(refr,2)\n",
    "    # refr[:,0:10]=0.\n",
    "    \n",
    "    return velr, refr, img, data_vel_s"
   ]
  },
  {
   "source": [
    "## Parallel implementation ##\n",
    "I will generate models in parallel by launching the dask.distributed scheduler on a local cluster, and have the serial modeling function run in parallel over the nodes."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's create a list to store results from each worker\n",
    "futures = []\n",
    "# Then, I initiate a dask client\n",
    "from dask.distributed import Client, LocalCluster\n",
    "cluster = LocalCluster(n_workers=n_samples) #threads_per_worker=1 #?\n",
    "client = Client(cluster)\n",
    "print(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallel modeling implementation\n",
    "start = timer()\n",
    "# Distribute one model function per worker\n",
    "for i in range(n_samples):\n",
    "    futures.append(client.submit(stdmodel,i))    \n",
    "# Collect results    \n",
    "VEL = [future.result()[0] for future in futures if(future.result()[0].min() == 1.5)]\n",
    "REF = [future.result()[1] for future in futures if(future.result()[0].min() == 1.5)]\n",
    "IMG = [future.result()[2] for future in futures if(future.result()[0].min() == 1.5)]\n",
    "VEL_MIG = [future.result()[3] for future in futures if(future.result()[0].min() == 1.5)]\n",
    "end = timer()\n",
    "print(end - start) # Time in seconds, e.g. 5.38091952400282\n",
    "\n",
    "# Get the total number of models collected\n",
    "print(len(VEL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data set in a HDF5 file\n",
    "train_path='/opt/resfoc/notebooks/external/train_models.h5'\n",
    "with h5py.File(train_path,'w') as hdf:\n",
    "    for i in range(len(VEL)):\n",
    "        hdf.create_dataset(\"velocity/vel\"+str(10000+i),data=VEL[i],dtype='float32')\n",
    "        hdf.create_dataset(\"velocity_mig/vel\"+str(10000+i),data=VEL_MIG[i],dtype='float32')\n",
    "        hdf.create_dataset(\"image/vel\"+str(10000+i),data=IMG[i],dtype='float32')\n",
    "        hdf.create_dataset(\"reflectivity/vel\"+str(10000+i),data=REF[i],dtype='float32')\n"
   ]
  },
  {
   "source": [
    "## Model plotting ##"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the HDF5 file with the following commands\n",
    "from utils import load_all_models2, pclip\n",
    "ref_p,ref_i,v,v0 = load_all_models2(train_path)[0:4]\n",
    "\n",
    "# Parameters for plotting\n",
    "rows = 1\n",
    "columns = 4\n",
    "fs=18\n",
    "plt.rc('xtick',labelsize=fs)\n",
    "plt.rc('ytick',labelsize=fs)\n",
    "\n",
    "#==========================\n",
    "# Plotting reflectivities =\n",
    "#==========================\n",
    "ix=0\t#random model index\n",
    "fig, axes = plt.subplots(nrows=rows,ncols=columns)\n",
    "vmin, vmax = pclip(ref_p[ix])\n",
    "# First model\n",
    "im1=axes[0].imshow(ref_p[ix].transpose(1,0),extent=(0,2.5,2.5,0), cmap='gray',vmin=vmin,vmax=vmax)\n",
    "axes[0].set_xlabel('km',fontsize=fs)\n",
    "axes[0].set_ylabel('km',fontsize=fs)\n",
    "divider = make_axes_locatable(axes[0])\n",
    "cax1 = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "fig.colorbar(im1, cax=cax1)\n",
    "# Second model\n",
    "vmin, vmax = pclip(ref_p[ix+1])\n",
    "im2=axes[1].imshow(ref_p[ix+1].transpose(1,0),extent=(0,2.5,2.5,0), cmap='gray',vmin=vmin,vmax=vmax)\n",
    "axes[1].set_xlabel('km',fontsize=fs)\n",
    "axes[1].set_ylabel('km',fontsize=fs)\n",
    "divider = make_axes_locatable(axes[1])\n",
    "cax2 = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "fig.colorbar(im2, cax=cax2)\n",
    "# Thrid model\n",
    "vmin, vmax = pclip(ref_p[ix+2])\n",
    "im3=axes[2].imshow(ref_p[ix+2].transpose(1,0),extent=(0,2.5,2.5,0), cmap='gray',vmin=vmin,vmax=vmax)\n",
    "axes[2].set_xlabel('km',fontsize=fs)\n",
    "axes[2].set_ylabel('km',fontsize=fs)\n",
    "divider = make_axes_locatable(axes[2])\n",
    "cax3 = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "fig.colorbar(im3, cax=cax3)\n",
    "# Fourth Model\n",
    "vmin, vmax = pclip(ref_p[ix+3])\n",
    "im4=axes[3].imshow(ref_p[ix+3].transpose(1,0),extent=(0,2.5,2.5,0), cmap='gray',vmin=vmin,vmax=vmax)\n",
    "axes[3].set_xlabel('km',fontsize=fs)\n",
    "axes[3].set_ylabel('km',fontsize=fs)\n",
    "divider = make_axes_locatable(axes[3])\n",
    "cax4 = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "fig.colorbar(im4, cax=cax4)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}